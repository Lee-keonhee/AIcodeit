---
layout: post
title:  "위클리 페이퍼 #9"
date:   2025-09-04 09:00:00 +0900
categories: [딥러닝, 인공지능, 데이터과학]
tags: [딥러닝 기초]
---

[1. Semantic Segmentation이란 무엇이며, 이미지 분류(Classification)와 어떤 차이가 있나요?]()

[2. Fully Convolutional Networks(FCN)의 주요 특징과 기존 CNN 기반 분류 모델과의 차이점은 무엇인가요?]()

[3. GAN에서 생성자(Generator)와 판별자(Discriminator)의 역할은 각각 무엇인가요?]()

[4. Diffusion 모델이 이미지 생성에서 어떻게 활용되며, 어떤 장점이 있나요?]()


---
# 1. Semantic Segmentation이란 무엇이며, 이미지 분류(Classification)와 어떤 차이가 있나요?
---

딥러닝에서 가장 기본적인 작업 중 하나가 **이미지 분류(Classification)**입니다. 분류는 입력된 이미지가 어떤 객체에 해당하는지 하나의 라벨을 출력하는 방식이죠. 예를 들어, 고양이 사진을 분류기에 넣으면 단순히 "Cat"이라는 결과만 반환됩니다.<br>
그런데 현실 세계의 이미지에서는 단일 객체만 있는 경우보다, 여러 객체가 한 이미지 안에 함께 존재하는 경우가 훨씬 많습니다. 또, 단순히 "이건 고양이"라고 끝나는 것이 아니라, 이미지 속에서 "고양이가 어디에 있고, 배경은 어디인지"와 같이 위치 정보가 필요한 경우도 많습니다.<br>
이때 사용하는 것이 바로 **Semantic Segmentation**입니다. 세그멘테이션은 **이미지의 픽셀 단위로 분류를 수행**하여, 각 **픽셀이 어떤 객체 클래스**에 속하는지 예측합니다. 즉, 분류가 이미지 전체를 하나의 라벨로 본다면, 세그멘테이션은 이미지의 세밀한 구조를 이해하고 시각적으로 해석할 수 있게 합니다.
아래 그림을 예시를 들어 보겠습니다.
- 이미지 분류: "이 사진은 고양이 사진이다."
- 세그멘테이션: "이 사진 속 왼쪽 아래에 있는 고양이 픽셀은 모두 Cat, 오른쪽 위 하늘은 Sky, 바닥은 Ground"
<br>
이처럼, 세그멘테이션은 **객체 인식(Object Detection)**보다도 더 세밀한 단계로, 이미지 속 픽셀 단위 레벨에서 객체를 이해하는 강력한 방법입니다.

<div>
    <img src="{{"/assets/images/classification_segmentation.png" | relative_url }}" width="500" height="200" alt="cat_segmentation" style="display: block; margin: 0 auto;>
    <p style="text-align: center; margin-top: 10px; font-weight: bold;">[그림] 이미지 설명: Classification vs Segmentation 결과 비교</p>
</div>

---
# 2. Fully Convolutional Networks(FCN)의 주요 특징과 기존 CNN 기반 분류 모델과의 차이점은 무엇인가요?
---

CNN(Convolutional Neural Network)은 딥러닝의 발전을 이끈 핵심 모델입니다. 기본적인 CNN은 여러 층의 Convolution + Pooling 연산을 거치면서 특징을 추출하고, 마지막에는 Fully Connected Layer를 통해 "이 이미지는 Cat일 확률: 0.9, Dog일 확률: 0.1"처럼 단일 벡터 출력을 만듭니다.
하지만 이 구조는 분류 문제에는 적합해도, 세그멘테이션처럼 픽셀 단위 출력을 내야 하는 문제에는 적합하지 않았습니다. 왜냐하면 Fully Connected Layer가 출력 크기를 고정해버리기 때문에, 공간적 위치 정보가 모두 손실되기 때문입니다.
이를 해결하기 위해 나온 것이 **Fully Convolutional Networks (FCN)**입니다.

## 2.1. FCN의 핵심 특징

### 2.1.1 완전연결층 제거
- CNN의 마지막 FC Layer 대신, Convolution과 Upsampling만 사용합니다. 덕분에 입력 이미지 크기에 제약이 줄어듭니다.
### 2.1.2 픽셀 단위 출력 가능
-  업샘플링(Deconvolution)을 통해 입력 이미지와 동일한 크기의 Segmentation Mask를 출력할 수 있습니다.
### 2.1.3 End-to-End 학습
분류 모델처럼 별도의 후처리 과정 없이, 이미지 입력 → 픽셀 단위 예측까지 한 번에 학습할 수 있습니다.

## 2.2 기존 CNN과의 차이
- CNN: 최종 출력이 1 x N 클래스 벡터
- FCN: 최종 출력이 H x W x N 클래스 맵

즉, CNN은 “이미지 전체가 무슨 클래스인지”만 말해주지만, FCN은 “이미지 속 어떤 위치가 무슨 클래스인지”까지 알려줍니다.

📌 이미지 예시 위치
(좌) CNN 분류 구조 다이어그램: 입력 → Conv/Pooling 반복 → FC → Class
(우) FCN 구조 다이어그램: 입력 → Conv → 업샘플링 → 픽셀 단위 Segmentation Map
이미지 설명: CNN과 FCN의 구조 비교

---
# 3. GAN에서 생성자(Generator)와 판별자(Discriminator)의 역할은 각각 무엇인가요?
---

GAN(Generative Adversarial Network)은 2014년 Ian Goodfellow가 제안한 이후, 이미지 생성 분야에서 폭발적인 성과를 거둔 모델입니다. GAN은 이름 그대로 두 네트워크가 서로 적대적으로 경쟁하면서 학습을 진행합니다.

Generator (G)
입력: 랜덤 노이즈 벡터
출력: 실제와 비슷한 가짜 이미지
목표: 판별자를 속일 수 있을 만큼 사실적인 이미지를 생성하는 것

Discriminator (D)
입력: 진짜 이미지 또는 생성자가 만든 가짜 이미지
출력: 입력이 진짜인지 가짜인지 확률
목표: 생성자의 가짜 이미지를 잡아내는 것

이 두 모델은 일종의 **적대적 게임(Adversarial Game)**을 합니다.
생성자는 점점 더 진짜 같은 이미지를 만들고, 판별자는 점점 더 잘 속아넘어가지 않도록 발전합니다.
최종적으로는 생성자가 만든 이미지가 진짜와 구별되지 않을 정도로 발전하게 됩니다.
GAN은 단순한 이미지 생성뿐만 아니라, 스타일 변환(예: Monet 그림체 변환), 초해상도(해상도 개선), 데이터 증강, 심지어 음악 생성까지 확장되어 활용되고 있습니다.

📌 이미지 예시 위치
GAN 기본 구조 다이어그램:
노이즈 z → Generator → 가짜 이미지
진짜 이미지 & 가짜 이미지 → Discriminator → 판별 결과
이미지 설명: GAN의 Generator–Discriminator 구조

---
# 4. Diffusion 모델이 이미지 생성에서 어떻게 활용되며, 어떤 장점이 있나요?
---

최근 가장 주목받고 있는 이미지 생성 모델은 Diffusion 모델입니다. GAN이 2015~2020년대를 휩쓸었다면, 2021년 이후에는 Stable Diffusion 같은 확산 기반 모델이 대세가 되었습니다.

✅ Diffusion 모델의 기본 아이디어
Forward 과정 (학습): 원본 이미지를 점차 노이즈화하여, 결국에는 순수한 노이즈로 변환
Reverse 과정 (생성): 순수한 노이즈에서 시작해, 학습한 역과정을 거쳐 점진적으로 이미지를 복원
즉, Diffusion은 노이즈 제거(Denoising) 과정을 학습하는 모델이라고 볼 수 있습니다.

✅ 장점
고품질 이미지 생성
GAN보다 훨씬 정교하고 디테일이 살아 있는 고해상도 이미지를 생성할 수 있습니다.
학습 안정성
GAN은 Generator–Discriminator 균형이 무너지면 학습이 망가지는 경우가 많지만, Diffusion은 상대적으로 안정적입니다.
모드 붕괴 감소
GAN은 종종 "비슷한 이미지"만 계속 생성하는 문제(mode collapse)가 있는데, Diffusion은 더 다양한 샘플을 생성할 수 있습니다.

✅ 응용
예술 작품 생성
Text-to-Image (텍스트 프롬프트 기반 이미지 생성)
이미지 복원 (낡은 사진 복구, 노이즈 제거)
데이터 증강

📌이미지 예시 위치
(좌) 깨끗한 이미지 → 점점 노이즈 추가 → 완전한 노이즈
(우) 순수 노이즈 → 점점 복원 → 최종 고품질 이미지
이미지 설명: Diffusion 모델의 Forward & Reverse 과정