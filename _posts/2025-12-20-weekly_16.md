---
layout: post
title: AI 모델 웹 통합 및 배포 아키텍처
date: 2025-12-22
categories:
  - 배포
  - 웹개발
tags:
  - streamlit
  - fastapi
  - docker
  - deployment
  - architecture
---

# AI 모델 웹 통합 및 배포 아키텍처

## 목차
1. [Streamlit을 활용한 AI 모델 웹 애플리케이션 통합](#section1)
2. [FastAPI 기반 AI 모델 웹 API 구조 설계](#section2)
3. [실전 AI 서비스 아키텍처: 이미지 생성 플랫폼 사례](#section3)

---

## 1. Streamlit을 활용한 AI 모델 웹 애플리케이션 통합 {#section1}

### 1단계: 모델 로드

**목표**: 애플리케이션 시작 시 모델을 효율적으로 메모리에 로드

핵심 개념:
- **세션 상태 활용**: Streamlit의 `@st.cache_resource` 데코레이터로 모델 재로드 방지
- **지연 로딩**: 필요한 시점에만 모델 초기화하여 초기 구동 시간 단축
- **다중 모델 관리**: 여러 모델이 필요한 경우 딕셔너리로 관리

주요 고려사항:
- **메모리 효율성**: 모델 크기가 큰 경우 양자화 모델 사용
- **버전 관리**: 모델 파일명에 버전 포함하여 추적성 확보
- **오류 처리**: 모델 로드 실패 시 사용자 친화적 에러 메시지 표시

모델 로드 패턴:
```
Singleton Pattern 적용
├── 첫 실행: 모델 파일 읽기 → 메모리 로드 → 캐싱
├── 이후 실행: 캐시된 모델 재사용
└── 세션 종료: 자동 메모리 해제
```

최적화 팁:
- 모델 파일은 `/models` 디렉토리에 중앙 집중 관리
- ONNX/TensorRT 등 최적화된 포맷 사용 권장
- 개발 환경에서는 경량 모델로 테스트 후 프로덕션에서 전환

---

### 2단계: 사용자 입력 처리

**목표**: 직관적인 UI로 다양한 형태의 입력 데이터 수집

입력 타입별 처리:

**이미지 입력**
- 파일 업로더를 통한 이미지 수집
- 지원 포맷: JPG, PNG, WEBP 등
- 전처리: 리사이징, 정규화, 텐서 변환
- 미리보기 제공으로 사용자 확인 가능

**텍스트 입력**
- 단일 라인: 짧은 쿼리, 키워드
- 멀티 라인: 긴 문서, 프롬프트
- 토큰 제한 안내 및 실시간 카운터

**구조화된 입력**
- 슬라이더: 연속적 파라미터 (온도, 확률 등)
- 드롭다운: 카테고리 선택 (모델 종류, 스타일 등)
- 체크박스: 옵션 선택 (후처리 적용 여부 등)

입력 검증 체크리스트:
- **형식 검증**: 파일 확장자, 크기 제한 확인
- **범위 검증**: 수치 입력의 최소/최대값 확인
- **필수 입력 확인**: 실행 전 모든 필수 필드 입력 검증
- **보안 검증**: 악성 파일 업로드 방지 (MIME 타입 체크)

사용자 경험 향상:
- **진행 상황 표시**: `st.progress()`, `st.spinner()` 활용
- **입력 예시 제공**: 샘플 데이터 제공으로 사용 방법 안내
- **실시간 피드백**: 입력값 변경 시 즉각적인 UI 반응

---

### 3단계: 결과 출력 및 시각화

**목표**: 모델 추론 결과를 사용자가 이해하기 쉽게 표현

출력 타입별 처리:

**이미지 결과**
- 원본-결과 비교 뷰 (컬럼 레이아웃)
- 다운로드 버튼으로 결과 이미지 저장
- 메타데이터 표시 (해상도, 처리 시간 등)

**텍스트 결과**
- 코드 블록: 구조화된 텍스트 (JSON, 코드)
- 마크다운: 포맷팅된 설명, 요약
- 하이라이팅: 중요 부분 강조

**수치 결과**
- 신뢰도 점수: 프로그레스 바로 시각화
- 메트릭 카드: 주요 지표 한눈에 표시
- 비교표: 여러 결과 간 성능 비교

고급 시각화:

**대화형 차트**
- Plotly/Altair로 인터랙티브 그래프
- 확대/축소, 필터링 기능
- 데이터 포인트 hover 시 상세 정보

**다중 결과 탐색**
- 탭으로 여러 출력 결과 구분
- 갤러리 뷰: 여러 생성 결과 그리드 표시
- 페이지네이션: 대량 결과 처리

**피드백 수집**
- 좋아요/싫어요 버튼
- 자유 텍스트 피드백 입력
- 데이터베이스 저장으로 모델 개선에 활용

성능 최적화:
- 대용량 결과는 썸네일 먼저 표시
- 무한 스크롤 대신 페이지네이션 사용
- 캐싱으로 동일 입력 재처리 방지

---

## 2. FastAPI 기반 AI 모델 웹 API 구조 설계 {#section2}

### 전체 디렉토리 구조

프로젝트 루트를 기준으로 한 추천 구조:

```
project_root/
├── app/
│   ├── main.py              # 애플리케이션 진입점
│   ├── config.py            # 설정 관리
│   ├── dependencies.py      # 의존성 주입
│   │
│   ├── api/                 # API 라우터
│   │   ├── __init__.py
│   │   ├── v1/              # API 버전 관리
│   │   │   ├── __init__.py
│   │   │   ├── predict.py   # 추론 엔드포인트
│   │   │   ├── health.py    # 헬스체크
│   │   │   └── feedback.py  # 피드백 수집
│   │
│   ├── models/              # ML 모델 관련
│   │   ├── __init__.py
│   │   ├── loader.py        # 모델 로딩 로직
│   │   ├── inference.py     # 추론 실행
│   │   └── preprocessing.py # 전처리 파이프라인
│   │
│   ├── schemas/             # Pydantic 모델
│   │   ├── __init__.py
│   │   ├── request.py       # 요청 스키마
│   │   └── response.py      # 응답 스키마
│   │
│   ├── core/                # 핵심 유틸리티
│   │   ├── __init__.py
│   │   ├── logger.py        # 로깅 설정
│   │   ├── errors.py        # 커스텀 예외
│   │   └── middleware.py    # 미들웨어
│   │
│   └── utils/               # 공통 유틸리티
│       ├── __init__.py
│       ├── image.py         # 이미지 처리
│       └── validation.py    # 입력 검증
│
├── tests/                   # 테스트 코드
│   ├── test_api.py
│   └── test_models.py
│
├── models/                  # 모델 파일 저장
│   └── model_v1.onnx
│
├── requirements.txt         # 의존성 패키지
├── Dockerfile              # 컨테이너 빌드
└── .env                    # 환경 변수
```

---

### 핵심 컴포넌트 설명

**1. main.py - 애플리케이션 진입점**

역할:
- FastAPI 앱 인스턴스 생성
- 라우터 등록 및 미들웨어 설정
- 전역 예외 핸들러 정의
- 시작/종료 이벤트 핸들러

주요 설정:
- CORS 정책 구성
- API 문서화 메타데이터
- 글로벌 에러 핸들링
- 모델 초기화 (startup 이벤트)

---

**2. api/v1/ - API 라우터 계층**

**predict.py - 추론 엔드포인트**
- `POST /v1/predict`: 메인 추론 API
- 요청 타입별 처리 (이미지, 텍스트, 멀티모달)
- 비동기 처리로 높은 처리량 확보
- 배치 추론 지원 (여러 입력 동시 처리)

**health.py - 헬스체크**
- `GET /health`: 기본 상태 확인
- `GET /health/ready`: 서비스 준비 상태 (모델 로드 완료)
- `GET /health/live`: 프로세스 생존 확인
- 로드밸런서와 오케스트레이션 도구에서 활용

**feedback.py - 피드백 수집**
- `POST /v1/feedback`: 사용자 피드백 저장
- 추론 결과에 대한 만족도, 이슈 리포팅
- 모델 재학습 데이터로 활용

---

**3. models/ - ML 모델 계층**

**loader.py - 모델 로딩**
- Singleton 패턴으로 모델 중복 로드 방지
- 여러 버전의 모델 동적 전환
- 오류 발생 시 폴백 모델 로드

**inference.py - 추론 실행**
- 배치 처리 최적화
- GPU/CPU 자동 선택
- 타임아웃 설정으로 무한 대기 방지

**preprocessing.py - 전처리**
- 입력 데이터 정규화
- 크기 조정, 포맷 변환
- 데이터 증강 (필요 시)

---

**4. schemas/ - 데이터 검증**

**request.py - 요청 스키마**
- 필드 타입 및 제약 조건 정의
- 자동 검증 및 에러 메시지 생성
- 예시 데이터 포함으로 API 문서 개선

**response.py - 응답 스키마**
- 일관된 응답 포맷 보장
- 메타데이터 포함 (처리 시간, 모델 버전 등)
- 에러 응답 표준화

---

**5. core/ - 핵심 인프라**

**logger.py - 로깅**
- 구조화된 로그 (JSON 포맷)
- 로그 레벨별 분리 (INFO, WARNING, ERROR)
- 로그 로테이션 및 압축

**errors.py - 예외 처리**
- 커스텀 예외 클래스 정의
- HTTP 상태 코드 매핑
- 사용자 친화적 에러 메시지

**middleware.py - 미들웨어**
- 요청/응답 로깅
- 처리 시간 측정
- 요청 ID 추적 (분산 추적)

---

### API 버전 관리 전략

**v1, v2 디렉토리 분리**
- 하위 호환성 유지하며 새 기능 추가
- 레거시 클라이언트 지원
- 점진적 마이그레이션 가능

**버전별 라우트 접두사**
```
/v1/predict  ← 안정 버전
/v2/predict  ← 신규 기능 (베타)
/latest/predict  ← 최신 버전 자동 연결
```

**Deprecation 정책**
- v1 종료 최소 6개월 전 공지
- 응답 헤더에 deprecation 경고 포함
- 마이그레이션 가이드 문서 제공

---

### 성능 최적화 고려사항

**비동기 처리**
- 모든 I/O 작업 async/await 사용
- 동시 요청 처리량 극대화
- 블로킹 작업은 스레드 풀로 분리

**연결 풀링**
- 데이터베이스 연결 재사용
- 외부 API 호출 최적화
- 리소스 고갈 방지

**캐싱 전략**
- 자주 사용되는 전처리 결과 캐싱
- Redis로 추론 결과 임시 저장
- 동일 입력 중복 처리 방지

**배치 처리**
- 여러 요청 그룹화하여 GPU 활용도 증가
- Dynamic batching으로 지연 시간과 처리량 균형
- 타임아웃 설정으로 무한 대기 방지

---

## 3. 실전 AI 서비스 아키텍처: 이미지 생성 플랫폼 사례 {#section3}

### 서비스 개요

**서비스명**: CreativeAI Studio
**기능**: 텍스트 프롬프트 기반 이미지 생성 및 편집
**타겟**: 크리에이터, 마케터, 디자이너
**월간 사용자**: 100만 명 (동시 접속 1만 명 가정)

핵심 기능:
- 텍스트-이미지 생성 (Stable Diffusion 기반)
- 이미지 업스케일링 (초해상도)
- 스타일 전이 (Style Transfer)
- 배경 제거 및 객체 분리

---

### 전체 시스템 아키텍처

```
[사용자 레이어]
    │
    ├─ 웹 브라우저 (React SPA)
    ├─ 모바일 앱 (Flutter)
    └─ API 클라이언트 (서드파티)
    │
    ▼
[CDN & Load Balancer]
    │
    ├─ Cloudflare CDN (정적 파일)
    └─ AWS ALB (API 트래픽)
    │
    ▼
[API Gateway Layer]
    │
    └─ Kong API Gateway
        ├─ 인증/인가 (JWT)
        ├─ Rate Limiting
        ├─ API 버전 라우팅
        └─ 로깅/모니터링
    │
    ▼
[Application Layer]
    │
    ├─ FastAPI 서버 (Auto-scaling)
    │   ├─ Pod 1: Predict API
    │   ├─ Pod 2: Predict API
    │   ├─ Pod N: Predict API
    │   └─ Health Check & Metrics
    │
    └─ Streamlit 대시보드 (내부 관리)
    │
    ▼
[Inference Layer]
    │
    ├─ GPU Node Pool
    │   ├─ NVIDIA T4 (비용 최적화)
    │   └─ NVIDIA A100 (고성능)
    │
    └─ Model Serving
        ├─ TensorRT Optimized Models
        ├─ ONNX Runtime
        └─ Model Registry (MLflow)
    │
    ▼
[Data Layer]
    │
    ├─ PostgreSQL (사용자, 메타데이터)
    ├─ Redis (캐싱, 세션)
    ├─ S3 (이미지 저장)
    └─ Elasticsearch (검색, 로그)
    │
    ▼
[Monitoring & Logging]
    │
    ├─ Prometheus (메트릭 수집)
    ├─ Grafana (대시보드)
    ├─ ELK Stack (로그 분석)
    └─ Sentry (에러 추적)
```

---

### 컨테이너화 및 오케스트레이션 (Docker & Kubernetes)

**Docker 이미지 구조**

```
Base Image (ubuntu:22.04)
    │
    ├─ Python 3.11
    ├─ CUDA Toolkit 12.1
    ├─ cuDNN 8.9
    │
    ▼
ML Dependencies Image
    │
    ├─ PyTorch 2.1
    ├─ TensorRT 8.6
    ├─ ONNX Runtime GPU
    │
    ▼
Application Image
    │
    ├─ FastAPI App Code
    ├─ Model Files (COPY)
    └─ Configuration
```

**Kubernetes 배포 전략**

**Deployment 구성**
- FastAPI: 최소 3개 Pod (HPA로 최대 20개)
- GPU Node Pool: 전용 노드 그룹 (Taints & Tolerations)
- Resource Limits: CPU 2코어, Memory 8GB, GPU 1개
- Health Probe: Liveness (30초), Readiness (10초)

**Service 타입**
- FastAPI: ClusterIP (내부 통신)
- Ingress: NGINX Ingress Controller
- Load Balancing: Round-robin with session affinity

**Storage**
- PersistentVolume: 모델 파일 공유 (ReadOnlyMany)
- EmptyDir: 임시 전처리 데이터
- ConfigMap: 환경별 설정 주입

---

### 보안 아키텍처

**인증 및 인가**

**JWT 기반 인증**
- Access Token: 15분 유효 (짧은 수명)
- Refresh Token: 7일 유효 (Rotation 정책)
- Token Blacklist: Redis에 무효화 토큰 저장

**API Key 관리**
- 서드파티 클라이언트용 API Key 발급
- 사용량 추적 및 쿼터 제한
- 자동 만료 및 재발급 기능

**CORS 설정**

허용 Origin 관리:
- 프로덕션: `https://creativeai.studio`
- 스테이징: `https://staging.creativeai.studio`
- 개발: `http://localhost:3000`

정책:
- Credentials: `true` (쿠키 허용)
- Methods: `GET, POST, PUT, DELETE`
- Headers: `Content-Type, Authorization`
- Max Age: 3600초 (preflight 캐싱)

**데이터 보안**

**전송 암호화**
- TLS 1.3 강제 (HSTS 헤더)
- Certificate Pinning (모바일 앱)

**저장 암호화**
- S3 Server-Side Encryption (SSE-KMS)
- PostgreSQL Transparent Data Encryption
- Redis 통신 암호화 (TLS)

**입력 검증**
- 파일 업로드: 크기 제한 10MB
- MIME 타입 화이트리스트
- 이미지 메타데이터 스캔 (악성코드 방지)
- SQL Injection 방지 (Parameterized Query)

---

### 멀티유저 요청 처리 전략

**비동기 처리 아키텍처**

**Celery Task Queue**

구조:
```
FastAPI (Producer)
    │
    ▼
RabbitMQ (Message Broker)
    │
    ├─ Queue: image_generation (높은 우선순위)
    ├─ Queue: upscaling (중간 우선순위)
    └─ Queue: batch_processing (낮은 우선순위)
    │
    ▼
Celery Workers (Consumers)
    │
    ├─ GPU Worker Pool (4 workers)
    └─ CPU Worker Pool (8 workers)
```

처리 흐름:
1. FastAPI가 요청 수신 → 즉시 Task ID 반환 (202 Accepted)
2. Celery가 백그라운드에서 작업 처리
3. 클라이언트가 `/status/{task_id}` 폴링
4. 완료 시 결과 URL 반환 (S3 Presigned URL)

**WebSocket 실시간 업데이트**

양방향 통신:
- 작업 진행률 실시간 전송 (0%, 25%, 50%, 75%, 100%)
- 대기열 위치 알림
- 완료 즉시 푸시 알림

연결 관리:
- Connection Pool 제한 (최대 10,000)
- Heartbeat (30초마다 Ping/Pong)
- 자동 재연결 (Exponential Backoff)

**대기 큐 관리**

**우선순위 시스템**
- Premium 사용자: Priority 1 (즉시 처리)
- 일반 사용자: Priority 2 (선착순)
- 무료 사용자: Priority 3 (리소스 여유 시)

**공정성 보장**
- Max Concurrent Requests per User: 3개
- Rate Limiting: 100 requests/hour (사용자별)
- Exponential Backoff: 과도한 재시도 방지

**부하 분산**
- GPU 사용률 기반 스케줄링
- 작업 크기 추정 (복잡도 계산)
- 긴 작업은 별도 큐로 분리

---

### 클라우드 배포 구조 (AWS 기준)

**리전 및 가용 영역**

Primary Region: `ap-northeast-2` (서울)
- AZ-1: 주 워크로드
- AZ-2: 고가용성 복제
- AZ-3: 재해 복구

Secondary Region: `us-west-2` (오리건)
- Disaster Recovery (DR)
- 글로벌 사용자 레이턴시 감소

**컴퓨팅 리소스**

**EKS 클러스터 구성**
```
Control Plane (AWS Managed)
    │
    ├─ API Node Group (t3.large)
    │   └─ 3-10 nodes (Auto-scaling)
    │
    ├─ GPU Node Group (p3.2xlarge)
    │   └─ 2-8 nodes (Spot Instances)
    │
    └─ DB/Cache Node Group (r5.xlarge)
        └─ 2 nodes (Fixed)
```

**Auto-scaling 정책**
- Target CPU: 70%
- Target Memory: 80%
- Scale-up: 2분 내
- Scale-down: 10분 대기 (안정화)

**네트워크 구성**

**VPC 설계**
```
VPC (10.0.0.0/16)
    │
    ├─ Public Subnet (DMZ)
    │   ├─ NAT Gateway
    │   ├─ Bastion Host
    │   └─ Load Balancer
    │
    ├─ Private Subnet (Application)
    │   ├─ EKS Worker Nodes
    │   └─ Fargate Pods
    │
    └─ Private Subnet (Data)
        ├─ RDS (Multi-AZ)
        └─ ElastiCache
```

**보안 그룹 규칙**
- ALB → EKS: 포트 80, 443
- EKS → RDS: 포트 5432
- EKS → Redis: 포트 6379
- 모든 Outbound 허용 (NAT Gateway 경유)

**스토리지 전략**

**S3 버킷 구조**
```
s3://creativeai-prod/
    │
    ├─ users/
    │   └─ {user_id}/
    │       ├─ originals/    (원본 이미지)
    │       └─ generated/    (생성 이미지)
    │
    ├─ models/
    │   ├─ stable-diffusion-v2.1/
    │   └─ upscaler-v1/
    │
    └─ temp/                 (24시간 후 자동 삭제)
```

**Lifecycle 정책**
- Standard: 최근 30일 접근 데이터
- Intelligent-Tiering: 31-90일
- Glacier: 90일 이상 미접근
- 삭제: 2년 후 자동 제거

**데이터베이스 아키텍처**

**RDS PostgreSQL (Multi-AZ)**
- Instance: db.r5.2xlarge (8 vCPU, 64GB RAM)
- Storage: 1TB gp3 (IOPS 12,000)
- Replica: 1개 Read Replica (읽기 부하 분산)
- Backup: 매일 자동 백업 (7일 보존)

**ElastiCache Redis (Cluster Mode)**
- Node: cache.r5.large
- Shards: 3개 (데이터 분산)
- Replicas: 각 샤드당 1개 (HA)
- 사용처: 세션, 캐싱, Rate Limiting

---

### 모니터링 및 로깅 전략

**메트릭 수집 (Prometheus + Grafana)**

**애플리케이션 메트릭**
- Request Rate (RPS): 초당 요청 수
- Error Rate: 4xx, 5xx 응답 비율
- Latency Percentiles: P50, P95, P99
- Queue Depth: 대기 중인 작업 수

**인프라 메트릭**
- CPU/Memory/Disk 사용률
- GPU 사용률 및 온도
- Network I/O
- Pod Restart Count

**비즈니스 메트릭**
- Daily Active Users (DAU)
- 이미지 생성 성공률
- 평균 처리 시간
- 사용자당 요청 수

**대시보드 구성**
- Overview: 전체 시스템 상태 (1분 갱신)
- API: 엔드포인트별 성능 (실시간)
- Infrastructure: 리소스 사용률 (5초 갱신)
- Business: KPI 추적 (시간별)

**로그 관리 (ELK Stack)**

**로그 수집 파이프라인**
```
Application Logs
    │
    ├─ Fluentd (Log Collector)
    │   └─ Kubernetes DaemonSet
    │
    ▼
Elasticsearch Cluster
    │
    ├─ Index: logs-api-{YYYY.MM.DD}
    ├─ Index: logs-celery-{YYYY.MM.DD}
    └─ Index: logs-nginx-{YYYY.MM.DD}
    │
    ▼
Kibana Dashboard
```

**로그 레벨 전략**
- DEBUG: 개발 환경만
- INFO: 정상 요청/응답 (샘플링 10%)
- WARNING: 비정상적이지만 처리 가능한 상황
- ERROR: 실패한 요청, 예외 발생
- CRITICAL: 시스템 장애

**로그 보존 정책**
- Hot (0-7일): 전체 로그 (빠른 검색)
- Warm (8-30일): 압축 저장
- Cold (31-90일): S3 아카이브
- 삭제 (90일 후)

**구조화된 로그 포맷 (JSON)**
```json
{
  "timestamp": "2025-12-22T10:30:45.123Z",
  "level": "INFO",
  "service": "fastapi-api",
  "trace_id": "abc123xyz",
  "user_id": "user_456",
  "endpoint": "/v1/predict",
  "method": "POST",
  "status_code": 200,
  "latency_ms": 1234,
  "message": "Image generated successfully"
}
```

**알림 설정 (PagerDuty 연동)**

**심각도별 알림 정책**

**P1 - Critical (즉시 대응)**
- 조건: Error Rate > 5% (5분간)
- 액션: SMS + 전화 + Slack
- 대응: 온콜 엔지니어 즉시 확인

**P2 - High (30분 내 대응)**
- 조건: Latency P95 > 5초
- 액션: Slack + 이메일
- 대응: 담당자 확인

**P3 - Medium (업무 시간 내 대응)**
- 조건: Queue Depth > 1000
- 액션: Slack 알림
- 대응: 모니터링 강화

**알림 채널 분리**
- #alerts-critical: P1 알림
- #alerts-warning: P2, P3 알림
- #alerts-info: 일일 리포트, 배포 알림

---

### 배포 전략 및 CI/CD

**GitOps 기반 배포**

```
GitHub Repository
    │
    ├─ feature/* → PR 생성
    │
    ▼
GitHub Actions (CI)
    │
    ├─ Lint & Test
    ├─ Build Docker Image
    ├─ Security Scan (Trivy)
    └─ Push to ECR
    │
    ▼
ArgoCD (CD)
    │
    ├─ Dev Environment (자동 배포)
    ├─ Staging (자동 배포)
    └─ Production (수동 승인)
```

**Canary Deployment**

단계별 출시:
1. 5% 트래픽 → Canary Pod (10분 모니터링)
2. 에러율 < 1% 확인 → 50% 트래픽
3. 최종 확인 → 100% 트래픽
4. 문제 발생 시 자동 롤백

메트릭 기반 자동 판단:
- Error Rate 증가 → 롤백
- Latency 2배 증가 → 일시 중지
- 메모리 누수 감지 → 롤백

**Blue-Green Deployment (데이터베이스 변경 시)**

프로세스:
1. Green 환경 준비 (신규 버전)
2. 데이터베이스 마이그레이션 (Backward Compatible)
3. 트래픽 100% Blue 유지 (검증)
4. DNS/Load Balancer 전환 → Green
5. Blue 환경 대기 (1시간 후 제거)

---

### 재해 복구 및 고가용성

**백업 전략**

**데이터베이스**
- 자동 백업: 매일 새벽 2시 (UTC)
- Point-in-Time Recovery: 최근 7일
- 스냅샷: 주간 (4주 보존)
- Cross-Region Replication: DR 리전 복제

**모델 파일**
- S3 Versioning 활성화
- Cross-Region Replication
- Glacier Deep Archive (1년 이상)

**복구 시간 목표 (RTO/RPO)**
- RTO: 1시간 (서비스 복구 시간)
- RPO: 5분 (데이터 손실 허용 시간)
- 목표 가용성: 99.9% (월 43분 다운타임 허용)

**장애 시나리오별 대응**

**AZ 장애**
- 자동 Failover (다른 AZ로 전환)
- 트래픽 재분배 (30초 내)
- 영향: 없음 (무중단)

**Region 장애**
- Route53 Health Check → DR 리전 활성화
- RTO: 30분 (수동 개입 필요)
- 데이터 동기화 확인 후 서비스 재개

**데이터베이스 장애**
- Read Replica 승격 (자동)
- 복구 시간: 3-5분
- 트랜잭션 손실: 최대 5분

---

### 비용 최적화 전략

**컴퓨팅 비용 절감**

**Spot Instances 활용**
- GPU 워크로드의 70%를 Spot으로 운영
- 예상 비용 절감: 60-70%
- Spot Interruption Handler로 안전한 종료

**Auto-scaling 최적화**
- 사용 패턴 분석 (피크: 저녁 7-11시)
- 스케줄링: 새벽 시간대 최소 노드
- 예측 기반 스케일링 (Karpenter 사용)

**스토리지 비용 절감**

**S3 Intelligent-Tiering**
- 자동 계층 전환으로 30% 절감
- 접근 패턴 분석 후 적용

**CloudFront CDN**
- 원본 요청 90% 감소
- 글로벌 엣지 캐싱으로 대역폭 비용 절감

**모니터링 비용 관리**
- 로그 샘플링 (전체 → 10%)
- 메트릭 집계 간격 조정 (1초 → 15초)
- 장기 보존 데이터 압축

---

### 보안 컴플라이언스 및 감사

**GDPR 준수**

개인정보 처리:
- 데이터 최소화 원칙 (필요한 정보만 수집)
- 사용자 동의 관리 (Opt-in)
- 잊힐 권리 (계정 삭제 시 30일 내 완전 삭제)

데이터 처리 기록:
- 처리 활동 로그 (누가, 언제, 무엇을)
- 감사 추적 (Audit Trail)
- 정기 보고서 생성

**보안 감사**

정기 점검:
- 분기별 침투 테스트
- 월간 취약점 스캔 (Nessus)
- 코드 정적 분석 (SonarQube)

인증 및 규정:
- SOC 2 Type II 인증
- ISO 27001 준수
- PCI-DSS (결제 정보 처리 시)

**접근 제어**

IAM 정책:
- Least Privilege Principle (최소 권한)
- Role-based Access Control (RBAC)
- Multi-Factor Authentication (MFA) 강제

감사 로그:
- CloudTrail로 모든 API 호출 기록
- GuardDuty로 이상 행위 탐지
- 관리자 작업 Slack 실시간 알림

---

## 정리

| 항목                 | 핵심 내용                                       | 주요 도구/기술                         |
| ------------------ | ------------------------------------------- | -------------------------------- |
| **Streamlit 통합**   | 모델 로드 → 입력 처리 → 결과 시각화                     | st.cache_resource, Plotly        |
| **FastAPI 구조**    | 모듈화된 라우터, 스키마 기반 검증, 비동기 처리                | Pydantic, async/await            |
| **컨테이너화**         | Docker 멀티 스테이지 빌드, Kubernetes 오케스트레이션       | Docker, K8s, Helm                |
| **보안**            | JWT 인증, CORS 정책, TLS 암호화                    | OAuth2, Let's Encrypt            |
| **멀티유저 처리**       | Celery 비동기 큐, WebSocket 실시간 업데이트            | RabbitMQ, Celery, Socket.IO      |
| **클라우드 배포**       | EKS 기반, Multi-AZ, Auto-scaling              | AWS EKS, RDS, S3                 |
| **모니터링**          | Prometheus 메트릭, ELK 로그, Grafana 대시보드       | Prometheus, Elasticsearch, Kibana |
| **CI/CD**          | GitOps, Canary 배포, 자동 롤백                    | GitHub Actions, ArgoCD           |
| **재해 복구**         | Multi-Region, 자동 백업, RTO/RPO 정의            | Route53, S3 Replication          |
| **비용 최적화**        | Spot Instance, S3 Lifecycle, CDN 캐싱        | AWS Spot, CloudFront             |
