---
layout: post
title:  "위클리 페이퍼 #8"
date:   2025-08-17 09:00:00 +0900
categories: [딥러닝, 인공지능, 데이터과학]
tags: [딥러닝 기초]
---

[1. YOLO(You Only Look Once) 모델의 주요 특징과 장점은 무엇인가요?](##1-YOLO의 주요 특징 및 장점)

[2. mAP(mean Average Precision)의 개념이 무엇이며 객체 인식에서 어떻게 활용되는지 설명해주세요.](##2-mAP의 개념과 활용)


---
## 1. YOLO(You Only Look Once) 모델의 주요 특징과 장점은 무엇인가요?
---

### 1.1 YOLO의 버전별 특징
<br>

#### 1.1.1 YOLOv1
2016년 출시된 YOLOv1은 객체 탐지 분야에 혁신을 가져온 최초의 One-stage (단일 단계) 모델입니다. 이미지 전체를 단 한 번만 보고 바로 바운딩 박스와 객체 클래스를 예측하는 방식을 채택했습니다. 이 모델은 입력 이미지를 고정된 크기의 그리드(Grid)로 분할하고, 각 그리드 셀이 경계 상자(Bounding Box)와 해당 객체의 클래스 확률을 직접 예측하도록 설계되었습니다. 백본(Backbone) 네트워크로는 Darknet을 사용했습니다.

이러한 YOLOv1은 당시 다른 객체 탐지 모델들, 특히 Two-stage 방식의 모델들에 비해 압도적으로 빠른 속도라는 큰 장점을 가졌으며, 전체 탐지 과정이 단일 네트워크 내에서 이루어지는 End-to-End 학습이 가능했습니다.
<br>

#### 1.1.2 YOLOv2
2017년에 발표된 YOLOv2는 이전 버전의 YOLOv1이 가진 장점인 속도를 유지하면서도 정확도를 크게 향상시킨 모델입니다. 백본 네트워크로 Darknet-19를 채택하여 특징 추출 능력을 강화했습니다.

정확도 향상을 위해 가장 중요한 변화는 Faster R-CNN에서 영감을 받은 앵커 박스(Anchor Box) 개념의 도입입니다. YOLOv2는 K-means 클러스터링을 사용하여 학습 데이터셋에 최적화된 미리 정의된 앵커 박스들을 활용하여 객체의 다양한 형태와 크기를 더 잘 예측할 수 있게 했습니다. 또한, 다중 스케일(Multi-scale) 학습 기법을 적용하여 다양한 해상도의 이미지로 훈련함으로써 모델의 강건성을 높였습니다. 작은 객체의 특징 정보를 더 잘 활용하기 위해 고해상도 특징 맵을 직접 연결하는 Passthrough Layer를 도입하기도 했습니다.

이러한 개선을 통해 YOLOv2는 이전 모델과 유사한 빠른 추론 속도를 유지하면서도 훨씬 더 높은 탐지 정확도를 달성했습니다.
<br>

#### 1.1.3 YOLOv3
2018년에 출시된 YOLOv3는 더욱 깊고 복잡한 네트워크 구조를 통해 정확도를 크게 끌어올렸습니다. 더 강력한 특징 추출을 위해 Darknet-53을 백본 네트워크로 사용했으며, 이는 ImageNet 벤치마크에서도 우수한 성능을 보였습니다.

YOLOv3의 핵심 개선점 중 하나는 Feature Pyramid Network (FPN) 구조와 Skip connection을 활용한 multi-scale detection의 도입입니다. 이를 통해 3가지 다른 스케일의 특징 맵에서 객체 탐지를 수행할 수 있게 되어, 다양한 크기의 객체를 특히 작은 객체에 대한 탐지 정확도를 크게 향상시켰습니다. 또한, 분류 손실 함수로 시그모이드(Sigmoid)와 Binary Cross-Entropy (이진 교차 엔트로피)를 기반으로 한 Logistic Classification Loss를 사용하여 다중 라벨 분류 문제를 더 효과적으로 처리할 수 있게 했습니다. 이러한 발전은 YOLOv3가 실시간 속도를 유지하면서도 매우 높은 정확도를 달성하는 데 기여했습니다.    
<br>

#### 1.1.4 YOLOv4
2020년에 발표된 YOLOv4는 최신 딥러닝 기법들을 광범위하게 적용하여 정확도와 속도 모두에서 최고 수준의 성능을 달성한 모델입니다. 이 버전은 단순히 새로운 아키텍처를 제시하기보다는, **BoF (Bag of Freebies)**와 **BoS (Bag of Specials)**라는 전략을 통해 다양한 최적화 기법들을 효율적으로 결합한 것이 특징입니다.

BoF에는 학습 시 정확도를 향상시키는 데이터 증강 기법인 Mosaic 데이터 증강 등이 포함되며, BoS에는 모델 아키텍처를 개선하는 CSPNet 기반의 백본 및 PANet 구조의 Neck, 그리고 Mish 활성화 함수 적용 등이 있습니다. YOLOv4는 CSPDarknet53을 백본으로, SPP와 PAN을 각각 Neck과 헤드로 사용하여 SOTA(State-of-the-Art) 수준의 성능과 실시간 추론 속도를 모두 제공하는 강력한 모델로 자리매김했습니다.
<br>

#### 1.1.5 YOLOv5
2020년에 Ultralytics가 PyTorch 프레임워크로 공개한 YOLOv5는 YOLOv4와 거의 동시에 발표되었지만, 뛰어난 사용 편의성과 유연성으로 빠르게 인기를 얻었습니다. YOLOv5는 PyTorch 생태계에 최적화된 구현으로, 모델을 쉽게 불러오고 학습시키며 배포할 수 있는 장점을 가집니다.

이 버전은 데이터에 맞춰 앵커 박스를 자동으로 학습하는 기능을 포함하여 사용자 편의성을 높였으며, 모델 크기별로 Nano, Small, Medium, Large, XLarge 등 다양한 프리셋을 제공하여 사용자가 프로젝트 요구사항에 맞춰 모델을 선택할 수 있도록 했습니다. YOLOv5는 강력한 추론 성능과 함께 직관적인 사용법으로 딥러닝 커뮤니티에서 매우 활발하게 사용되는 버전이 되었습니다.
<br>

#### 1.1.6 YOLOv6
2022년에 Meituan(메이투안)에서 공개한 YOLOv6는 특히 빠른 추론 속도와 산업 응용에 초점을 맞춘 모델입니다. 이는 RepVGG 계열의 백본 아키텍처를 활용하여 고도로 최적화된 구조를 가지며, 양자화(Quantization)와 같은 배포 최적화 기술에 강점을 보입니다.

YOLOv6는 특히 모바일 기기나 엣지 디바이스 등 리소스가 제한된 환경에서의 효율적인 추론을 목표로 설계되어, 특정 하드웨어에서 이전 버전보다 더 빠른 속도를 제공하며 산업 현장에서의 객체 탐지 애플리케이션에 적합한 성능을 보여줍니다.
<br>

#### 1.1.7 YOLOv7
2022년에 YOLOv4와 YOLOv5의 핵심 개발자 중 일부가 발표한 YOLOv7은 지금까지 공개된 모든 실시간 객체 탐지기 중에서 가장 높은 속도-정확도 트레이드오프를 자랑합니다. 이 모델은 **E-ELAN (Extended Efficient Layer Aggregation Network)**이라는 새로운 효율적인 아키텍처 설계와 Compound Model Scaling 전략을 통해 네트워크의 처리 효율성을 극대화했습니다.

YOLOv7은 효율적인 학습 전략과 함께 강력한 모델 성능을 보여주며, 다양한 데이터셋과 환경에서 SOTA 수준의 결과를 달성하며 실시간 객체 탐지 분야의 선두 주자 중 하나로 자리매김했습니다.
<br>

#### 1.1.8 YOLOv8
2023년에 Ultralytics가 발표한 YOLOv8은 이전 버전인 YOLOv5의 뒤를 잇는 최신 세대의 모델입니다. YOLOv8의 가장 큰 특징은 앵커 박스(Anchor Box)의 개념을 사용하지 않는 Anchor-free Detection 방식을 채택하여 모델의 헤드를 단순화하고 예측 프로세스를 간소화했다는 점입니다.

또한, C2f 모듈이라는 효율적인 빌딩 블록을 백본과 Neck 부분에 도입하여 특징 추출 효율을 높였으며, **새로운 손실 함수(VFL, DFL)**들을 사용하여 분류 및 회귀 성능을 개선했습니다. YOLOv8은 단순한 객체 탐지뿐만 아니라, 분류(Classification)와 세분화(Segmentation) 기능까지 통합하여 하나의 프레임워크에서 다양한 컴퓨터 비전 작업을 지원하는 종합적인 솔루션으로 발전했습니다. 이는 사용자들에게 뛰어난 성능과 함께 높은 활용 편의성을 제공합니다.
<br>

#### 1.1.9 YOLOv9
2024년에 YOLOv7의 주요 개발자들이 공개한 YOLOv9는 딥러닝 네트워크에서 발생하는 정보 손실 문제에 대한 근본적인 해결책을 제시합니다. 기존 심층 신경망에서 데이터가 깊은 계층을 통과하면서 점진적으로 유용한 정보가 소실되는 현상인 "정보 병목(Information Bottleneck)"과 "데이터 손실(Data Loss)" 문제를 해결하는 데 초점을 맞췄습니다.

이를 위해 **Generalized Efficient Layer Aggregation Network (GELAN)**라는 새로운 네트워크 아키텍처와 **Programmable Gradient Information (PGI)**이라는 혁신적인 기법을 도입했습니다. GELAN은 파라미터 활용도와 계산 효율성을 최적화하고, PGI는 보조 브랜치를 통해 학습 과정에서 중요한 기울기 정보를 유지하고 완전한 정보를 전달함으로써 신뢰할 수 있는 기울기를 생성하고 수렴 속도를 향상시킵니다. 이러한 기술들을 통해 YOLOv9는 이전 모델들보다 더 높은 정확도를 훨씬 저렴한 계산 비용으로 달성하며 실시간 객체 탐지 분야에서 새로운 벤치마크를 제시했습니다.
<br>

#### 1.1.10 YOLOv10
2024년에 발표된 YOLOv10은 End-to-End 객체 탐지라는 새로운 방향을 제시합니다. 가장 큰 특징은 기존 YOLO 모델들이 예측 후 'NMS(Non-Maximum Suppression)'라는 후처리 과정을 거쳐 중복된 바운딩 박스를 제거했던 것과 달리, NMS 과정을 아키텍처 설계 단계에서 제거하여 네트워크 자체적으로 최종 바운딩 박스를 예측한다는 점입니다. 이러한 NMS-free 구조는 전체 파이프라인을 간소화하고 추론 속도를 더욱 향상시키며, 실시간 성능을 극대화합니다. YOLOv10은 지연 시간에 민감한 엣지 디바이스나 실시간 애플리케이션에 최적화되어, 뛰어난 속도와 효율성을 자랑하면서도 이전 버전과 유사하거나 더 높은 정확도를 달성하여 실용성이 매우 높은 모델로 평가받고 있습니다.
<br>

#### 1.1.11 YOLOv11
2024년에 Ultralytics가 공개한 YOLOv11은 듀얼 헤드(Dual-Head) 아키텍처를 도입하여 작은 객체 탐지 성능을 향상시켰습니다. 새로운 손실 함수와 학습 전략을 통해 더 적은 파라미터로도 높은 정확도를 달성하며 효율성과 다목적성을 모두 갖춘 모델입니다.
<br>

#### 1.1.12 YOLOv12
2025년 2월에 출시된 YOLOv12는 주의 중심(Attention-Centric) 아키텍처를 도입하여 YOLO 시리즈의 새로운 방향을 제시했습니다. 영역 어텐션(Area Attention) 메커니즘을 통해 정확도를 높이면서도 실시간 추론 속도를 유지하며, 이전 모델들보다 더 효율적인 성능을 보여줍니다.
#### 모델별 추가 및 변화 내용

| 버전	| 주요 추가/변화 내용 |
|-------|-------------------|
| YOLOv1 |	• 최초의 One-stage 모델 <br> • 그리드 시스템, Darknet 백본 도입 |
| YOLOv2 |	• 정확도 향상 <br> • 앵커 박스(Anchor Box) 도입 (K-means 클러스터링) <br> • 다중 스케일 학습, Passthrough Layer 추가 |
| YOLOv3 |	• 더 깊은 네트워크 (Darknet-53) <br> • FPN(Feature Pyramid Network) 구조 도입 <br> • 3가지 다른 스케일에서 객체 탐지 |
| YOLOv4 |	• 최신 기법의 총집합 <br> • BoF(Bag of Freebies), BoS(Bag of Specials) 전략 <br> • Mosaic 데이터 증강, CSPDarknet53 백본 사용 |
| YOLOv5 |	• PyTorch 기반 구현 (Ultralytics) <br> • 다양한 모델 크기 (Nano, Small 등) 제공 <br> • 뛰어난 사용 편의성 및 유연성 |
| YOLOv6 |	• 산업용 응용에 최적화 <br> • RepVGG 백본, 양자화에 강점 <br> • 매우 빠른 추론 속도 |
| YOLOv7 |	• 역대 최고의 속도-정확도 트레이드오프 <br> • E-ELAN 아키텍처, Compound Model Scaling 도입 |
| YOLOv8 |	• Anchor-free 방식 채택 <br> • C2f 모듈 도입 <br> • 분류, 세분화 등 다양한 작업 통합 |
| YOLOv9 |	• GELAN, PGI 도입 <br> • 학습 중 발생하는 정보 손실 문제 해결 <br> • 효율적인 파라미터 활용 |
| YOLOv10 |	• NMS-free 아키텍처 <br> • 후처리 과정 제거, End-to-End 추론 <br> • 추론 지연 시간(Latency) 최소화 |
| YOLOv11 |	• Ultralytics 개발 <br> • 듀얼 헤드 아키텍처로 작은 객체 탐지 개선 <br> • 더 적은 파라미터로 높은 정확도 달성 |
| YOLOv12 |	• Ultralytics 개발 <br> • 어텐션 중심(Attention-Centric) 아키텍처 <br> • 영역 어텐션(A²), R-ELAN 등 도입 <br> • YOLO 공식 모델 중 최초의 Transformer 기반 접근 |


---
## 2. mAP(mean Average Precision)의 개념이 무엇이며 객체 인식에서 어떻게 활용되는지 설명해주세요.

---

**mAP (mean Average Precision)** 는 객체 탐지 모델의 성능을 종합적으로 평가하는 지표입니다. 모델이 이미지 내의 여러 객체들을 얼마나 정확하게 **탐지(Bounding Box의 위치)** 하고 **분류(객체 클래스)** 하는지 측정합니다.

mAP를 이해하기 위해서는 몇 가지 핵심 개념을 알아야 합니다.

### 2.1 mAP의 구성 요소
1. IoU (Intersection over Union):
   - 모델이 예측한 바운딩 박스(Predicted BBox)와 실제 정답 바운딩 박스(Ground Truth BBox)가 얼마나 겹치는지를 측정하는 비율입니다.
   - IoU = (두 박스의 겹치는 영역) / (두 박스를 합친 전체 영역)  
   - IoU 값이 높을수록 모델이 객체의 위치를 더 정확하게 예측했다는 의미입니다. 일반적으로 모델의 예측이 'True Positive (정답)'로 인정받기 위한 최소 IoU 임계값을 설정합니다 (예: 0.5, 0.75).
   <br>
2. Precision (정밀도) & Recall (재현율):
   - Precision: 모델이 '긍정이라고 예측한 것들 중에서 실제로 긍정인 비율' 입니다. ( TP / (TP + FP) )
     - 객체 탐지에서는 "모델이 탐지한 바운딩 박스들 중 실제 객체를 정확히 찾아낸 비율"을 의미합니다. (오탐지(False Positive)가 적을수록 높습니다.)
   - Recall: 실제 '긍정인 것들 중에서 모델이 긍정이라고 예측한 비율' 입니다. ( TP / (TP + FN) )
     - 객체 탐지에서는 "실제 이미지에 있는 모든 객체들 중 모델이 찾아낸 비율"을 의미합니다. (놓친 객체(False Negative)가 적을수록 높습니다.)
   - 객체 탐지 모델은 각 예측에 대해 '신뢰도 점수(Confidence Score)'를 출력하는데, 이 신뢰도 점수의 임계값을 조절함에 따라 Precision과 Recall이 변화합니다. 신뢰도 임계값을 높이면 Precision은 올라가지만 Recall은 낮아지고, 그 반대도 마찬가지입니다.
   <br>
3. Precision-Recall (P-R) Curve:
   - 모델의 신뢰도 점수 임계값을 0부터 1까지 변화시키면서 얻어지는 모든 Precision과 Recall 쌍을 그래프로 그린 것입니다.
   - 일반적으로 Recall을 x축, Precision을 y축으로 그립니다.
   <br>
4. AP (Average Precision):
   - 특정 하나의 객체 클래스에 대한 P-R 곡선 아래의 면적을 의미합니다.  
   - 이 면적이 넓을수록 해당 클래스에 대한 모델의 성능이 좋다고 평가합니다. 즉, 모든 Recall 수준에서 높은 Precision을 유지한다는 의미입니다.
   <br>
5. mAP (mean Average Precision):
   - 전체 데이터셋에 있는 모든 객체 클래스(예: dog, cat, car 등)에 대한 AP 값을 각각 계산한 뒤, 그 값들을 평균 낸 것입니다.  
   - 이는 모델이 다양한 종류의 객체를 전반적으로 얼마나 잘 탐지하는지 나타내는 포괄적인 성능 지표입니다.

### 2.2 IoU 임계값의 중요성 (mAP@50 vs mAP@50-95)
mAP는 IoU 임계값을 어떻게 설정하느냐에 따라 값이 달라집니다.

- mAP@0.5 (또는 mAP@50):
  - IoU 임계값을 0.5로 설정하여 계산한 mAP입니다.  
  - 예측 박스가 정답 박스와 절반 이상만 겹쳐도 정답으로 인정하는 비교적 관대한 기준입니다. PASCAL VOC 챌린지에서 주로 사용되었습니다.
- mAP@0.5:0.95 (또는 mAP@50-95):
  - IoU 임계값을 0.5부터 0.95까지 0.05 단위로 (0.5, 0.55, ..., 0.95) 총 10개의 임계값에 대해 mAP를 각각 계산한 후, 이 10개의 mAP 값들을 모두 평균 낸 것입니다.
  - 예측 박스가 정답 박스와 아주 정교하게 겹쳐야 정답으로 인정하는 엄격하고 포괄적인 기준입니다. COCO 챌린지에서 사용되는 표준 지표이며, 실제 환경에서의 모델 정밀도를 더 잘 반영합니다.

### 2.3 객체 탐지에서의 활용
  mAP는 객체 탐지 모델에서 다음과 같이 활용됩니다.

1. 성능 평가의 표준 지표: 개발된 객체 탐지 모델이 얼마나 잘 작동하는지 측정하는 가장 중요한 척도입니다. 모델의 전반적인 정확도와 위치 추정 능력을 동시에 평가합니다.
2. 모델 비교 및 벤치마킹: 다양한 객체 탐지 모델(예: YOLO, SSD, Faster R-CNN)의 성능을 객관적으로 비교하고, 특정 데이터셋에서 어떤 모델이 가장 우수한지 판단하는 기준이 됩니다. 새로운 모델이나 개선된 알고리즘을 발표할 때 이 mAP를 핵심 결과로 제시합니다.
3. 하이퍼파라미터 튜닝 및 모델 개선 가이드: 모델 학습 과정에서 손실 함수(Loss Function), 학습률(Learning Rate), 아키텍처 변경 등 다양한 하이퍼파라미터나 구조적 변화가 모델 성능에 어떤 영향을 미치는지 mAP를 통해 파악하고, 모델을 최적화하는 데 활용됩니다.
4. 연구 및 개발의 핵심 목표: 딥러닝 연구에서 새로운 객체 탐지 기술을 개발할 때, 목표 성능을 mAP 값으로 설정하고 이를 달성하기 위해 연구를 진행합니다.

결론적으로 mAP는 객체 탐지 모델의 종합적인 성능을 측정하고, 연구 및 산업 분야에서 모델을 개발하고 비교하는 데 있어 핵심적인 역할을 하는 매우 중요한 지표입니다.