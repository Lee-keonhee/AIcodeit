---
layout: post
title:  "위클리 페이퍼 #6"
date:   2025-08-17 09:00:00 +0900
categories: [딥러닝, 인공지능, 데이터과학]
tags: [딥러닝 기초]
---

[1. YOLO(You Only Look Once) 모델의 주요 특징과 장점은 무엇인가요?](#1-YOLO의 주요 특징 및 장점)

[2. mAP(mean Average Precision)의 개념이 무엇이며 객체 인식에서 어떻게 활용되는지 설명해주세요.](#2-mAP의 개념과 활용)


---
## 1. YOLO(You Only Look Once) 모델의 주요 특징과 장점은 무엇인가요?
---

### 1.1 YOLO의 버전별 특징
#### 1.1.1 YOLOv1
2016년 출시된 YOLOv1은 객체 탐지 분야에 혁신을 가져온 최초의 One-stage (단일 단계) 모델입니다. 이미지 전체를 단 한 번만 보고 바로 바운딩 박스와 객체 클래스를 예측하는 방식을 채택했습니다. 이 모델은 입력 이미지를 고정된 크기의 그리드(Grid)로 분할하고, 각 그리드 셀이 경계 상자(Bounding Box)와 해당 객체의 클래스 확률을 직접 예측하도록 설계되었습니다. 백본(Backbone) 네트워크로는 Darknet을 사용했습니다.

이러한 YOLOv1은 당시 다른 객체 탐지 모델들, 특히 Two-stage 방식의 모델들에 비해 압도적으로 빠른 속도라는 큰 장점을 가졌으며, 전체 탐지 과정이 단일 네트워크 내에서 이루어지는 End-to-End 학습이 가능했습니다.

#### 1.1.2 YOLOv2
2017년에 발표된 YOLOv2는 이전 버전의 YOLOv1이 가진 장점인 속도를 유지하면서도 정확도를 크게 향상시킨 모델입니다. 백본 네트워크로 Darknet-19를 채택하여 특징 추출 능력을 강화했습니다.

정확도 향상을 위해 가장 중요한 변화는 Faster R-CNN에서 영감을 받은 앵커 박스(Anchor Box) 개념의 도입입니다. YOLOv2는 K-means 클러스터링을 사용하여 학습 데이터셋에 최적화된 미리 정의된 앵커 박스들을 활용하여 객체의 다양한 형태와 크기를 더 잘 예측할 수 있게 했습니다. 또한, 다중 스케일(Multi-scale) 학습 기법을 적용하여 다양한 해상도의 이미지로 훈련함으로써 모델의 강건성을 높였습니다. 작은 객체의 특징 정보를 더 잘 활용하기 위해 고해상도 특징 맵을 직접 연결하는 Passthrough Layer를 도입하기도 했습니다.

이러한 개선을 통해 YOLOv2는 이전 모델과 유사한 빠른 추론 속도를 유지하면서도 훨씬 더 높은 탐지 정확도를 달성했습니다.

#### 1.1.3 YOLOv3
2018년에 출시된 YOLOv3는 더욱 깊고 복잡한 네트워크 구조를 통해 정확도를 크게 끌어올렸습니다. 더 강력한 특징 추출을 위해 Darknet-53을 백본 네트워크로 사용했으며, 이는 ImageNet 벤치마크에서도 우수한 성능을 보였습니다.

YOLOv3의 핵심 개선점 중 하나는 Feature Pyramid Network (FPN) 구조의 도입입니다. 이를 통해 3가지 다른 스케일의 특징 맵에서 객체 탐지를 수행할 수 있게 되어, 다양한 크기의 객체를 특히 작은 객체에 대한 탐지 정확도를 크게 향상시켰습니다. 또한, 분류 손실 함수로 시그모이드(Sigmoid)와 Binary Cross-Entropy (이진 교차 엔트로피)를 기반으로 한 Logistic Classification Loss를 사용하여 다중 라벨 분류 문제를 더 효과적으로 처리할 수 있게 했습니다. 이러한 발전은 YOLOv3가 실시간 속도를 유지하면서도 매우 높은 정확도를 달성하는 데 기여했습니다.    

#### 1.1.4 YOLOv4
2020년에 발표된 YOLOv4는 최신 딥러닝 기법들을 광범위하게 적용하여 정확도와 속도 모두에서 최고 수준의 성능을 달성한 모델입니다. 이 버전은 단순히 새로운 아키텍처를 제시하기보다는, **BoF (Bag of Freebies)**와 **BoS (Bag of Specials)**라는 전략을 통해 다양한 최적화 기법들을 효율적으로 결합한 것이 특징입니다.

BoF에는 학습 시 정확도를 향상시키는 데이터 증강 기법인 Mosaic 데이터 증강 등이 포함되며, BoS에는 모델 아키텍처를 개선하는 CSPNet 기반의 백본 및 PANet 구조의 Neck, 그리고 Mish 활성화 함수 적용 등이 있습니다. YOLOv4는 CSPDarknet53을 백본으로, SPP와 PAN을 각각 Neck과 헤드로 사용하여 SOTA(State-of-the-Art) 수준의 성능과 실시간 추론 속도를 모두 제공하는 강력한 모델로 자리매김했습니다.

#### 1.1.5 YOLOv5
2020년에 Ultralytics가 PyTorch 프레임워크로 공개한 YOLOv5는 YOLOv4와 거의 동시에 발표되었지만, 뛰어난 사용 편의성과 유연성으로 빠르게 인기를 얻었습니다. YOLOv5는 PyTorch 생태계에 최적화된 구현으로, 모델을 쉽게 불러오고 학습시키며 배포할 수 있는 장점을 가집니다.

이 버전은 데이터에 맞춰 앵커 박스를 자동으로 학습하는 기능을 포함하여 사용자 편의성을 높였으며, 모델 크기별로 Nano, Small, Medium, Large, XLarge 등 다양한 프리셋을 제공하여 사용자가 프로젝트 요구사항에 맞춰 모델을 선택할 수 있도록 했습니다. YOLOv5는 강력한 추론 성능과 함께 직관적인 사용법으로 딥러닝 커뮤니티에서 매우 활발하게 사용되는 버전이 되었습니다.

#### 1.1.6 YOLOv6
2022년에 Meituan(메이투안)에서 공개한 YOLOv6는 특히 빠른 추론 속도와 산업 응용에 초점을 맞춘 모델입니다. 이는 RepVGG 계열의 백본 아키텍처를 활용하여 고도로 최적화된 구조를 가지며, 양자화(Quantization)와 같은 배포 최적화 기술에 강점을 보입니다.

YOLOv6는 특히 모바일 기기나 엣지 디바이스 등 리소스가 제한된 환경에서의 효율적인 추론을 목표로 설계되어, 특정 하드웨어에서 이전 버전보다 더 빠른 속도를 제공하며 산업 현장에서의 객체 탐지 애플리케이션에 적합한 성능을 보여줍니다.

#### 1.1.7 YOLOv7
2022년에 YOLOv4와 YOLOv5의 핵심 개발자 중 일부가 발표한 YOLOv7은 지금까지 공개된 모든 실시간 객체 탐지기 중에서 가장 높은 속도-정확도 트레이드오프를 자랑합니다. 이 모델은 **E-ELAN (Extended Efficient Layer Aggregation Network)**이라는 새로운 효율적인 아키텍처 설계와 Compound Model Scaling 전략을 통해 네트워크의 처리 효율성을 극대화했습니다.

YOLOv7은 효율적인 학습 전략과 함께 강력한 모델 성능을 보여주며, 다양한 데이터셋과 환경에서 SOTA 수준의 결과를 달성하며 실시간 객체 탐지 분야의 선두 주자 중 하나로 자리매김했습니다.

#### 1.1.8 YOLOv8
2023년에 Ultralytics가 발표한 YOLOv8은 이전 버전인 YOLOv5의 뒤를 잇는 최신 세대의 모델입니다. YOLOv8의 가장 큰 특징은 앵커 박스(Anchor Box)의 개념을 사용하지 않는 Anchor-free Detection 방식을 채택하여 모델의 헤드를 단순화하고 예측 프로세스를 간소화했다는 점입니다.

또한, C2f 모듈이라는 효율적인 빌딩 블록을 백본과 Neck 부분에 도입하여 특징 추출 효율을 높였으며, **새로운 손실 함수(VFL, DFL)**들을 사용하여 분류 및 회귀 성능을 개선했습니다. YOLOv8은 단순한 객체 탐지뿐만 아니라, 분류(Classification)와 세분화(Segmentation) 기능까지 통합하여 하나의 프레임워크에서 다양한 컴퓨터 비전 작업을 지원하는 종합적인 솔루션으로 발전했습니다. 이는 사용자들에게 뛰어난 성능과 함께 높은 활용 편의성을 제공합니다.

#### 1.1.9 YOLOv9
2024년에 YOLOv7의 주요 개발자들이 공개한 YOLOv9는 딥러닝 네트워크에서 발생하는 정보 손실 문제에 대한 근본적인 해결책을 제시합니다. 기존 심층 신경망에서 데이터가 깊은 계층을 통과하면서 점진적으로 유용한 정보가 소실되는 현상인 "정보 병목(Information Bottleneck)"과 "데이터 손실(Data Loss)" 문제를 해결하는 데 초점을 맞췄습니다.

이를 위해 **Generalized Efficient Layer Aggregation Network (GELAN)**라는 새로운 네트워크 아키텍처와 **Programmable Gradient Information (PGI)**이라는 혁신적인 기법을 도입했습니다. GELAN은 파라미터 활용도와 계산 효율성을 최적화하고, PGI는 보조 브랜치를 통해 학습 과정에서 중요한 기울기 정보를 유지하고 완전한 정보를 전달함으로써 신뢰할 수 있는 기울기를 생성하고 수렴 속도를 향상시킵니다. 이러한 기술들을 통해 YOLOv9는 이전 모델들보다 더 높은 정확도를 훨씬 저렴한 계산 비용으로 달성하며 실시간 객체 탐지 분야에서 새로운 벤치마크를 제시했습니다.

#### 1.1.10 YOLOv10
2024년에 발표된 YOLOv10은 End-to-End 객체 탐지라는 새로운 방향을 제시합니다. 가장 큰 특징은 기존 YOLO 모델들이 예측 후 'NMS(Non-Maximum Suppression)'라는 후처리 과정을 거쳐 중복된 바운딩 박스를 제거했던 것과 달리, NMS 과정을 아키텍처 설계 단계에서 제거하여 네트워크 자체적으로 최종 바운딩 박스를 예측한다는 점입니다. 

이러한 NMS-free 구조는 전체 파이프라인을 간소화하고 추론 속도를 더욱 향상시키며, 실시간 성능을 극대화합니다. YOLOv10은 지연 시간에 민감한 엣지 디바이스나 실시간 애플리케이션에 최적화되어, 뛰어난 속도와 효율성을 자랑하면서도 이전 버전과 유사하거나 더 높은 정확도를 달성하여 실용성이 매우 높은 모델로 평가받고 있습니다.

#### 1.1.11 YOLOv11
2024년에 Ultralytics와 밀접하게 관련되어 출시된 YOLOv11은 높은 정확도와 매개변수 효율성에 중점을 둔 모델입니다. YOLOv10과 비교하여 모델 크기와 추론 속도에는 특정 시나리오에서 트레이드오프가 있을 수 있으나, YOLOv11은 뛰어난 탐지 정확도를 제공합니다. 

YOLOv11은 상대적으로 적은 수의 파라미터로 고성능을 달성하는 매개변수 효율성을 특징으로 하며, 다목적성을 통해 다양한 컴퓨터 비전 작업에 유연하게 활용될 수 있습니다. 고정밀 객체 감지가 필수적인 의료 영상 분석, 제조 품질 관리, 위성 이미지 분석 등 정확도가 최우선시되는 애플리케이션에 특히 적합한 모델로 평가됩니다.


---
## 2. mAP(mean Average Precision)의 개념이 무엇이며 객체 인식에서 어떻게 활용되는지 설명해주세요.

---
오토인코더(Autoencoder)는 입력 데이터를 압축하여 잠재 변수로 만든 다음, 이를 이용하여 원본 데이터와 유사하게 복원하는 딥러닝 신경망입니다.
그렇기 때문에 아래 그림과 처럼 오토인코더는 입력 데이터를 압축할 Encoder와 이를 다시 복원할 수 있는 Decoder로 구성이 되어 있습니다.
<br>
<img src="{{"/assets/images/autoencoder_model.png" | relative_url }}" width="500" height="400" alt="Autoencoder 모델">

오토인코더는 자체 입력 데이터를 재구성하도록 **비지도 학습**을 통해 훈련된 Encoder-Decoder 아키텍처를 의미합니다. 다양한 종류의 오토인코더가 특정 목표와 데이터 유형에 가장 적합하도록 인공 신경망의 특정 요소를 변경하지만, 다음과 같은 주요 공통된 구조를 가지고 있습니다.

- 인코더 (Encoder)
입력 데이터의 차원을 점진적으로 감소시켜, 데이터를 압축된 표현으로 인코딩하는 신경망 층입니다. 이 과정을 통해 데이터의 핵심 특징만 남게 됩니다.
- 잠재 공간 (Latent Space)
인코더의 최종 출력으로, 입력 데이터를 가장 압축적으로 표현한 것입니다. 이 층은 인코더 네트워크의 마지막이자 디코더 네트워크의 입력이 되며, 데이터 재구성에 필요한 최소한의 **중요한 특징(잠재 표현)**을 담고 있습니다.
- 디코더 (Decoder)
잠재 공간의 압축된 데이터를 받아, 원래 입력 데이터 형태로 재구성(압축 해제)하는 신경망 층입니다. 이 과정에서 층의 노드 수가 점진적으로 증가하며 원본과 유사한 출력을 만들어냅니다. 재구성된 출력과 원본 입력 간의 차이를 '재구성 오류'라고 하며, 이 오류를 최소화하는 방향으로 모델이 학습됩니다.

|  | 	인코더 (Encoder)         | 	디코더 (Decoder)            |
|--|------------------------|---------------------------|
| 역할 | 	원본 데이터를 압축하고 핵심 특징 추출 | 	압축된 특징을 받아 원본 데이터로 복원    |
| 목표 | 	고차원 데이터 -> 저차원 잠재 표현  | 	저차원 잠재 표현 -> 고차원 데이터 재구성 |
| 차원 | 	입력보다 출력 차원이 점진적으로 감소  | 	입력보다 출력 차원이 점진적으로 증가     |
| 입력 | 	원본 데이터                | 인코더의 출력 (잠재 공간 / 코드)      |
| 출력 | 	잠재 공간                 | 	재구성된 데이터                 |
