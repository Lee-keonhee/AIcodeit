---
layout: post
title:  "위클리 페이퍼 #6"
date:   2025-08-17 09:00:00 +0900
categories: [딥러닝, 인공지능, 데이터과학]
tags: [딥러닝 기초]
---
---
## 1. CNN을 구성하는 각 레이어의 역할
---

### CNN 모델
Convolutional Neural Network(CNN)은 기본적으로 아래 그림과 같은 형태로 이루어져 있습니다.
<br>
<img src="{{"/assets/images/cnn_model_1.png" | relative_url }}" width="600" height="400" alt="CNN 모델">

해당 CNN 모델의 구조를 조금 더 자세히 살펴보겠습니다. CNN 모델은 크게 두 부분으로 구성이 됩니다.
1. 특징 추출(Feature Extraction)
해당 부분은 주로 여러 개의 Convolutional Layer와 Max Pooling Layer가 반복적되는 형태로 되어있으며, Batch Normalization Layer가 들어가기도 합니다.
보통 이미지의 저수준부터 고수준까지의 특징을 추출하는 역할을 합니다.
<br>
- 컨볼루션 레이어 (Convolutional Layer)
  * 역할 
  이미지에서 선, 모서리, 질감 등과 같은 다양한 **특징**들을 추출합니다. 이미지의 공간 정보를 보존하면서 특징을 학습하는 것이 강점입니다.
  * 작동 방식
  **필터(Filter)** 또는 **커널(Kernel)**이 이미지 위를 이동하며 특징을 스캔하고 강조합니다. 학습을 통해 필터가 업데이트되어 특징을 잘 포착하게 됩니다.
  * 결과물
  여러 개의 **특징 맵(Feature Map)**을 생성합니다.
  * 특징
  Convolutional Layer의 경우, **Convolutional layer**, **Batch Normalization**, **Activation Function**을 포함하는 경우가 많으며, 각각 특징 추출, 출력 정규화 및 학습 안정화, 비선형성 부여의 역할을 가지고 있습니다.
<br>
- 풀링 레이어 (Pooling Layer)
  * 역할
  특징 맵의 크기를 줄여(다운샘플링) 계산량을 줄이고, 과적합을 방지하며, 모델이 이미지의 미세한 변화에 덜 민감해지도록(변이 불변성) 만듭니다.
  * 작동 방식 
  주로 **Max Pooling**을 사용해 특정 영역의 가장 큰 값을 선택하여 특징을 압축합니다.
  * 결과물
  크기가 줄어든 새로운 특징 맵을 생성합니다.
  <br>
2. 분류기(Classifier)
분류기에서는 이미 얻어진 Feature Map을 **Flatten**하여 1차원의 배열로 만들어, 기존의 MLP와 활성화함수를 이용하여 이미지를 분류합니다.
<br>
- 플래튼 레이어 (Flatten Layer)
  * 역할
  특징 추출 부분에서 생성된 2차원 또는 3차원 특징 맵 데이터를 완전 연결 계층에 입력하기 위해 1차원 배열(벡터)로 변환합니다.
<br>
- 완전 연결 계층 (Fully Connected Layer, Multi Layer Perceptron, FCL, MLP)
  * 역할
   1차원으로 펼쳐진 특징 벡터를 입력받아 최종 분류를 위한 복잡한 비선형 관계를 학습합니다. 여러 층으로 구성될 수 있습니다.
  * 특징
  MLP와 Activation Function으로 이루어져 있으며, 각각 데이터 분류 및 비선형성 부여의 역할을 한다. 마지막 Layer의 경우, Activation Function을 softmax를 활용하여 각 클래스에 속할 확률을 반환해준다. 
    


---
## 2. AutoEncoder의 Encoder와 Decoder
---
오토인코더(Autoencoder)는 입력 데이터를 압축하여 잠재 변수로 만든 다음, 이를 이용하여 원본 데이터와 유사하게 복원하는 딥러닝 신경망입니다.
그렇기 때문에 아래 그림과 처럼 오토인코더는 입력 데이터를 압축할 Encoder와 이를 다시 복원할 수 있는 Decoder로 구성이 되어 있습니다.
<br>
<img src="{{"/assets/images/autoencoder_model.png" | relative_url }}" width="500" height="400" alt="CNN 모델">

오토인코더는 자체 입력 데이터를 재구성하도록 **비지도 학습**을 통해 훈련된 Encoder-Decoder 아키텍처를 의미합니다. 다양한 종류의 오토인코더가 특정 목표와 데이터 유형에 가장 적합하도록 인공 신경망의 특정 요소를 변경하지만, 다음과 같은 주요 공통된 구조를 가지고 있습니다.

- 인코더 (Encoder)
입력 데이터의 차원을 점진적으로 감소시켜, 데이터를 압축된 표현으로 인코딩하는 신경망 층입니다. 이 과정을 통해 데이터의 핵심 특징만 남게 됩니다.
- 잠재 공간 (Latent Space)
인코더의 최종 출력으로, 입력 데이터를 가장 압축적으로 표현한 것입니다. 이 층은 인코더 네트워크의 마지막이자 디코더 네트워크의 입력이 되며, 데이터 재구성에 필요한 최소한의 **중요한 특징(잠재 표현)**을 담고 있습니다.
- 디코더 (Decoder)
잠재 공간의 압축된 데이터를 받아, 원래 입력 데이터 형태로 재구성(압축 해제)하는 신경망 층입니다. 이 과정에서 층의 노드 수가 점진적으로 증가하며 원본과 유사한 출력을 만들어냅니다. 재구성된 출력과 원본 입력 간의 차이를 '재구성 오류'라고 하며, 이 오류를 최소화하는 방향으로 모델이 학습됩니다.

|  | 	인코더 (Encoder)         | 	디코더 (Decoder)            |
|--|------------------------|---------------------------|
| 역할 | 	원본 데이터를 압축하고 핵심 특징 추출 | 	압축된 특징을 받아 원본 데이터로 복원    |
| 목표 | 	고차원 데이터 -> 저차원 잠재 표현  | 	저차원 잠재 표현 -> 고차원 데이터 재구성 |
| 차원 | 	입력보다 출력 차원이 점진적으로 감소  | 	입력보다 출력 차원이 점진적으로 증가     |
| 입력 | 	원본 데이터                | 인코더의 출력 (잠재 공간 / 코드)      |
| 출력 | 	잠재 공간                 | 	재구성된 데이터                 |

---
## 3. 오토 인코더의 적용 사례
---
- 데이터 압축
토인코더의 인코더는 원본 데이터를 더욱 작은 차원의 잠재 공간으로 변환합니다. 이 과정에서 불필요하거나 중복된 정보는 제거되고, 데이터의 핵심적인 특징만을 유지함으로써 효율적인 데이터 압축을 가능하게 합니다.
- 차원축소
인코더를 통해 원본 데이터는 낮은 차원의 잠재 공간으로 사영됩니다. 이는 기존의 PCA(주성분 분석)와 유사하게 데이터의 복잡성을 줄이면서도, 비선형적인 특징까지 학습하여 데이터의 본질적인 구조를 보다 효율적으로 포착함으로써 효과적인 차원 축소에 기여합니다.
- 이상 감지
이상치가 아닌 데이터의 경우, reconstruction된 데이터와 원본 데이터 간의 loss 값이 작지만, 이상치의 경우에는 데이터간의 loss 값이 커지게 되는데, 이러한 점을 이용하여 이상치를 탐지한다.
- 노이즈 제거
<img src="{{"/assets/images/autoencoder.png" | relative_url }}" width="300" height="200" alt="CNN 모델">

특히 **디노이징 오토인코더(Denoising Autoencoder)**의 경우, 모델은 의도적으로 노이즈가 추가된 데이터를 입력으로 받아 노이즈가 없는 원본 데이터를 복원하도록 학습됩니다. 이를 통해 모델은 데이터 내의 불필요한 노이즈를 걸러내고 순수한 본질적인 특징을 학습하여 깨끗한 데이터를 재구성할 수 있게 됩니다.
- 데이터 재구성
오토인코더의 학습 목표는 인코더를 통해 압축된 **잠재 표현**을 디코더를 이용하여 원본 입력 데이터와 최대한 유사하게 복원하는 것입니다. 이 재구성 과정은 모델이 데이터의 중요한 특징을 효과적으로 학습했음을 의미하며, 이 과정의 정확도를 통해 모델의 성능을 평가합니다.
- 데이터 생성
오토인코더는 데이터의 잠재 공간에 대한 표현을 학습합니다. 특히 **Variational Autoencoder(VAE)**와 같은 오토인코더의 변형 모델들은 학습된 잠재 공간에서 새로운 샘플을 추출하거나 조작하여, 원본 데이터와 유사하지만 이전에 없던 새로운 데이터를 생성하는 데 활용될 수 있습니다.

---
## 4. Encoder와 Decoder를 가진 다른 딥러닝 모델
---
Encoder와 Decoder를 가졌다고 해서, 모두 Autoencoder인 것은 아닙니다. Autoencoder는 Encoder와 decoder를 이용하여 데이터를 복원하는 신경망을 autoencoder라고 합니다. 그렇다면, 이렇게 Autoencoder 이외에 encoder와 decoder로 이루어진 모델은 어떠한 것이 있을까요?
<br>
- Seq2Seq 모델
  * 특징
  시퀀스 데이터를 다른 형태의 시퀀스 데이터로 변환하는 데 사용되는 모델 입니다. 주로 RNN(Recurrent Neural Network)계열 모델을 사용하여 인코더와 디코더를 구성합니다.
  * 작동방식
  Encoder : 입력 시퀀스(문장, 음성 특징)을 받아서 고정된 크기의 Context Vector로 압축
  Decoder : Context Vector를 원하는 출력 시퀀스(번역된 문장, 텍스트) 생성
<br>
- Transformer
  * 특징
  현재 자연어 처리(NLP)분야에서 가장 널리 사용되는 모델로, Attention 메커니즘으로 인코더와 디코더를 구성합니다
  * 작동방식
  Encoder : 입력 시퀀스의 모든 단어(Token)간의 관계를 Attention 매커니즘을 통해 계산하고 정보를 인코딩합니다.
  Decoder : 인코더의 출력과 현재까지 생성된 출력 토큰들을 바탕으로 다음 출력 토큰을 예측하며 시퀀스를 생성합니다.
<br>
- 이미지 캡션 모델
  * 특징
  이미지 데이터를 이용하여 이를 설명하는 시퀀스 데이터로 변환하는 데 사용되는 모델입니다. 주로 CNN-RNN, CNN-Transformer 모델을 사용합니다.
  * 작동방식
  Encoder : 주로 CNN(Convolutional Neural Network) (예: ResNet, VGG)을 사용하여 이미지에서 시각적 특징을 추출합니다.
  Decoder : 추출된 이미지 특징을 입력으로 받아 RNN 또는 트랜스포머 기반으로 이미지 설명을 텍스트 시퀀스로 생성합니다.